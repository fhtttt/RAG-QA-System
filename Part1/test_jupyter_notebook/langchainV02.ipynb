{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28838f5c-9edc-4328-8966-00d6bca61894",
   "metadata": {},
   "source": [
    "## 1. LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba5d406-2ec0-4963-9524-06433482814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from zhipuai import ZhipuAI\n",
    "load_dotenv()\n",
    "\n",
    "api_key=os.environ.get('ZHIPU_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f99adba-bb69-4756-932d-1ad75f8f11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"What is {topic}\")\n",
    "])\n",
    "\n",
    "chat = ChatZhipuAI(\n",
    "    zhipuai_api_key = api_key,\n",
    "    model=\"glm-4\",\n",
    "    max_tokens=1024,\n",
    "    temperature=0.8, \n",
    ")\n",
    "\n",
    "chain = prompt_template | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b00b028d-4471-4af5-b63b-25372842c558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='åŒ—äº¬çƒ¤é¸­ï¼ˆPeking duckï¼‰æ˜¯ä¸€é“äº«èª‰ä¸­å¤–çš„ä¸­åŽä¼ ç»Ÿåèœï¼ŒæºäºŽä¸­å›½åŒ—äº¬ï¼Œå…·æœ‰æ‚ ä¹…çš„åŽ†å²ã€‚å®ƒçš„åˆ¶ä½œå·¥è‰ºç‹¬ç‰¹ï¼Œé£Ÿç”¨æ—¶é€šå¸¸å°†çƒ¤åˆ¶å¥½çš„é¸­å­ç‰‡æˆè–„ç‰‡ï¼Œä¸Žè–„é¥¼ã€ç”œé¢é…±å’Œè‘±ä¸ä¸€èµ·å·èµ·é£Ÿç”¨ã€‚\\n\\nåŒ—äº¬çƒ¤é¸­çš„ç‰¹ç‚¹æ˜¯é¸­çš®é…¥è„†ï¼Œè‚‰è´¨é²œå«©ã€‚åœ¨çƒ¹é¥ªè¿‡ç¨‹ä¸­ï¼Œå¸ˆå‚…ä¼šåœ¨é¸­è…”å†…æ³¨å…¥çƒ­æ°´ï¼Œä½¿é¸­çš®ä¸Žé¸­è‚‰ä¹‹é—´å½¢æˆä¸€å±‚è–„è–„çš„è„‚è‚ªï¼Œè¿™æ ·åœ¨çƒ¤åˆ¶æ—¶ï¼Œè„‚è‚ªä¼šæº¶å…¥çš®ä¸­ï¼Œä½¿å¾—é¸­çš®æ—¢é…¥åˆè„†ã€‚ä¼ ç»Ÿä¸Šï¼ŒåŒ—äº¬çƒ¤é¸­é‡‡ç”¨æŒ‚ç‚‰æˆ–ç„–ç‚‰çš„æ–¹å¼çƒ¤åˆ¶ï¼Œè¿‡ç¨‹ä¸­è¿˜ä¼šä¸æ–­åœ°åœ¨é¸­çš®ä¸Šæ¶‚åˆ·èœ‚èœœæˆ–ç³–æ°´ï¼Œå¢žåŠ å…¶è‰²æ³½å’Œé£Žå‘³ã€‚\\n\\nåŒ—äº¬çƒ¤é¸­ä¸ä»…åœ¨ä¸­å›½æ·±å—æ¬¢è¿Žï¼Œä¹Ÿæ·±å—ä¸–ç•Œå„åœ°ç¾Žé£Ÿçˆ±å¥½è€…çš„å–œçˆ±ï¼Œæˆä¸ºå›½é™…å‹äººäº†è§£ä¸­å›½æ–‡åŒ–çš„ä¸€ä¸ªé‡è¦çª—å£ã€‚', response_metadata={'token_usage': {'completion_tokens': 179, 'prompt_tokens': 18, 'total_tokens': 197}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='run-d2ac2bec-e127-49f6-be89-64e09f4ef204-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\":\"Peking duck\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5013af8c-3b7e-4453-be5d-c478b549fa79",
   "metadata": {},
   "source": [
    "## 2. Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ca04f74-b69a-4a6e-9fc0-0d19b0a93029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install httpx_sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6206d3c-bb9d-4944-b497-d692f4d9c0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My custom handler, token: Why\n",
      "My custom handler, token:  don\n",
      "My custom handler, token: 't\n",
      "My custom handler, token:  bears\n",
      "My custom handler, token:  like\n",
      "My custom handler, token:  to\n",
      "My custom handler, token:  use\n",
      "My custom handler, token:  computers\n",
      "My custom handler, token: ?\n",
      "\n",
      "Because\n",
      "My custom handler, token:  they\n",
      "My custom handler, token:  prefer\n",
      "My custom handler, token:  to\n",
      "My custom handler, token:  keep\n",
      "My custom handler, token:  it\n",
      "My custom handler, token:  wild\n",
      "My custom handler, token:  and\n",
      "My custom handler, token:  un\n",
      "My custom handler, token: -b\n",
      "My custom handler, token: ear\n",
      "My custom handler, token: -\n",
      "My custom handler, token: able\n",
      "My custom handler, token: !\n",
      "My custom handler, token:  ðŸ˜„\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "class MyCustomHandler(BaseCallbackHandler):\n",
    "    # Every time there is a new token, you will call the function in it.\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        print(f\"My custom handler, token: {token}\")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\"Please tell me a joke about {animal}\"])\n",
    "\n",
    "\n",
    "llm = ChatZhipuAI(\n",
    "    zhipuai_api_key = api_key,\n",
    "    model=\"glm-4\",\n",
    "    max_tokens=1024,\n",
    "    temperature=0.8, \n",
    "    streaming=True,\n",
    "    callbacks=[MyCustomHandler()],\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"animal\": \"bear\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdd2b6ad-1506-4155-a1d0-b96b87f80c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76278/1271503365.py:5: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  llm = ChatZhipuAI(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't bears like to use computers?\n",
      "\n",
      "Because they prefer to keep things au naturel!"
     ]
    }
   ],
   "source": [
    "# Langchain official streamingstdoutcallback\n",
    "from langchain_core.callbacks.manager import CallbackManager\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm = ChatZhipuAI(\n",
    "    zhipuai_api_key = api_key,\n",
    "    model=\"glm-4\",\n",
    "    max_tokens=1024,\n",
    "    temperature=0.8, \n",
    "    streaming=True,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"animal\": \"bear\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421835b0-5066-425e-a25e-ee4f4a9cfdaf",
   "metadata": {},
   "source": [
    "## 3. Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e75514c7-9c8c-47d5-802d-ca1f2a40d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "memory.chat_memory.add_user_message(\"Hi\")\n",
    "memory.chat_memory.add_ai_message(\"Hi, how can I help you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b55f28c-f62b-4c3e-8871-bb2be8b5fd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Human: Hi\\nAI: Hi, how can I help you?'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98402119-226b-4447-a779-6aafcd7acd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e7d75e3-c640-4c15-9296-aaccfd32f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a chatbot who knows the chat_history\"\n",
    "        ),\n",
    " \n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat = ChatZhipuAI(\n",
    "    zhipuai_api_key = api_key,\n",
    "    model=\"glm-4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e249e8f9-f14b-4ab6-b13b-99e5e8cf9289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58bed745-0809-4bb9-97c9-658a273217f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot who knows the chat_history\n",
      "Human: Hi\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'Hi', 'chat_history': [HumanMessage(content='Hi'), AIMessage(content='### Conversation Summary:\\n\\nThe user greeted the chatbot. The chatbot acknowledged the greeting.\\n\\n---\\n\\nIf you have any questions or need further assistance, feel free to ask!')], 'text': '### Conversation Summary:\\n\\nThe user greeted the chatbot. The chatbot acknowledged the greeting.\\n\\n---\\n\\nIf you have any questions or need further assistance, feel free to ask!'}\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"question\": \"Hi\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8327b1c-c949-4ff6-91eb-98dfb98a3966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot who knows the chat_history\n",
      "Human: Hi\n",
      "AI: ### Conversation Summary:\n",
      "\n",
      "The user greeted the chatbot. The chatbot acknowledged the greeting.\n",
      "\n",
      "---\n",
      "\n",
      "If you have any questions or need further assistance, feel free to ask!\n",
      "Human: today is raining?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"question\": \"today is raining?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c4e3396-7f52-4f3e-be3a-f4607beaf0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot who knows the chat_history\n",
      "Human: Hi\n",
      "AI: ### Conversation Summary:\n",
      "\n",
      "The user greeted the chatbot. The chatbot acknowledged the greeting.\n",
      "\n",
      "---\n",
      "\n",
      "If you have any questions or need further assistance, feel free to ask!\n",
      "Human: today is raining?\n",
      "AI: As an AI, I don't have real-time data or the ability to check the weather. To find out if it's raining where you are, you can check a weather app or website, or simply look out the window. If you tell me your location, I can provide you with a general idea of the current weather based on some online sources, but it won't be as accurate as a dedicated weather service.\n",
      "Human: Can I go out to play\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'Can I go out to play', 'chat_history': [HumanMessage(content='Hi'), AIMessage(content='### Conversation Summary:\\n\\nThe user greeted the chatbot. The chatbot acknowledged the greeting.\\n\\n---\\n\\nIf you have any questions or need further assistance, feel free to ask!'), HumanMessage(content='today is raining?'), AIMessage(content=\"As an AI, I don't have real-time data or the ability to check the weather. To find out if it's raining where you are, you can check a weather app or website, or simply look out the window. If you tell me your location, I can provide you with a general idea of the current weather based on some online sources, but it won't be as accurate as a dedicated weather service.\"), HumanMessage(content='Can I go out to play'), AIMessage(content=\"Whether you can go out to play depends on several factors, such as the weather, your age, any safety considerations, and your personal preferences. If it's raining, you might want to consider indoor activities instead. If you're dressed for the rain (in rain gear and appropriate shoes), and it's safe to do so, you can still enjoy outdoor activities even in the rain.\\n\\nHere are some things to consider before deciding to go out:\\n\\n1. **Weather conditions**: Check if it's just a light rain or a heavy storm. A light rain might be enjoyable to play in, but heavy rain or thunderstorms are best avoided.\\n   \\n2. **Safety**: Make sure the area where you plan to play is safe, especially in wet conditions which can make surfaces slippery.\\n\\n3. **Clothing**: Wear appropriate clothing and footwear to keep you warm and dry.\\n\\n4. **Company**: It's more fun to play with friends or family, especially in the rain.\\n\\n5. **Indoor alternatives**: If the weather is too poor to go out, consider indoor activities like board games, movies, or a visit to a local indoor play area.\\n\\nUltimately, the decision is up to you and your guardians, taking into account all these factors.\")], 'text': \"Whether you can go out to play depends on several factors, such as the weather, your age, any safety considerations, and your personal preferences. If it's raining, you might want to consider indoor activities instead. If you're dressed for the rain (in rain gear and appropriate shoes), and it's safe to do so, you can still enjoy outdoor activities even in the rain.\\n\\nHere are some things to consider before deciding to go out:\\n\\n1. **Weather conditions**: Check if it's just a light rain or a heavy storm. A light rain might be enjoyable to play in, but heavy rain or thunderstorms are best avoided.\\n   \\n2. **Safety**: Make sure the area where you plan to play is safe, especially in wet conditions which can make surfaces slippery.\\n\\n3. **Clothing**: Wear appropriate clothing and footwear to keep you warm and dry.\\n\\n4. **Company**: It's more fun to play with friends or family, especially in the rain.\\n\\n5. **Indoor alternatives**: If the weather is too poor to go out, consider indoor activities like board games, movies, or a visit to a local indoor play area.\\n\\nUltimately, the decision is up to you and your guardians, taking into account all these factors.\"}\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"question\": \"Can I go out to play\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1cd998-bc66-4ff2-8787-c5119e938e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragqa_jl",
   "language": "python",
   "name": "ragqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
